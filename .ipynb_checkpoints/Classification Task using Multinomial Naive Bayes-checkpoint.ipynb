{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Task for Spambase Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am HsinYu Chang, currently master student in Data Informatics at USC. This is a classification task for a Spambase data set from UCI Machine Learning Repository. The following is the process I have done and details I would like to share, enjoy it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloading and Preprocessing the Spambase data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off the classification task, I first downloaded the Spambase data set and shuffled it in order to not being biased with some specific order by data collecting. The spam rate in the dataset is roughly 40%, which is not too imbalance to make a classification without preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from random import *\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam rate in dataset: 0.394\n"
     ]
    }
   ],
   "source": [
    "inputfile = 'spambase.data'\n",
    "spam = np.loadtxt(inputfile, delimiter = ',')\n",
    "np.random.shuffle(spam)\n",
    "print('Spam rate in dataset: %.3f' %(sum(spam[:, -1]==1)/len(spam)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spitting Dataset into Training Set and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, I splitted the data set into 70%-30%, leaving 30% as the test set to evaluate the performance of the final model. Before starting to train model, I checked on a dummy model to have a basic measure of performance even if simply guessing. With a baseline, I could have a better idea to see how well the model I achieve in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsize = int(0.7 * len(spam))\n",
    "traini = np.array(sample(range(0, len(spam)), trainsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam rate in train set: 0.396\n"
     ]
    }
   ],
   "source": [
    "X = spam[traini, :-1]\n",
    "y = spam[traini, -1]\n",
    "\n",
    "print('Spam rate in train set: %.3f' % (sum(y==1)/len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam rate in train set: 0.390\n"
     ]
    }
   ],
   "source": [
    "testX = np.delete(spam[:, :-1], traini, 0)\n",
    "testy = np.delete(spam[:, -1], traini, 0)\n",
    "\n",
    "print('Spam rate in train set: %.3f' % (sum(testy==1)/len(testy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Dummy Model) FPR: 0.390, FNR: 0.610, Overall Error: 0.476\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier()\n",
    "dummy.fit(X, y)\n",
    "predicty = dummy.predict(testX)\n",
    "tn, fp, fn, tp = confusion_matrix(testy, predicty).ravel()\n",
    "print('(Dummy Model) FPR: %.3f, FNR: %.3f, Overall Error: %.3f' % (fp/(fp+tn), fn/(fn+tp), (fn+fp)/(tn+fp+fn+tp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Searching on Training Set to Build Multinomial Naive Bayes Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I built a clssifier based on Multinomial Naive Bayes, which has a strong assumption that all features are independent to all the others. To build the model, I did a 5-fold grid search for hyperparameters, including alpha and prior probability, on the training set with using f1-score as the scoring measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter search for multinomialNB\n",
    "paramDict = {\"alpha\": [0.1, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "             'fit_prior' : [True, False],\n",
    "             'class_prior' : [None, [.4,.6], [.3, .7],[.2, .8]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 10\n",
    "multiNB = MultinomialNB()\n",
    "paraSearch = RandomizedSearchCV(multiNB, param_distributions = paramDict, n_iter=niter, cv=5, scoring = 'f1')\n",
    "paraSearch.fit(X, y)\n",
    "bestPara = paraSearch.cv_results_['params'][np.argmin(paraSearch.cv_results_['rank_test_score'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_prior': True, 'class_prior': [0.3, 0.7], 'alpha': 0.1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestPara\n",
    "#paraSearch.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step by Step on Building Multinomial Naive Bayes Model with 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result =[] \n",
    "kfold = KFold(n_splits=5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for traini, validi in kfold.split(X): \n",
    "    trainX, validX = X[traini, :], X[validi, :]\n",
    "    trainy, validy = y[traini], y[validi]\n",
    "    multiNB = MultinomialNB(alpha = bestPara['alpha'], \n",
    "                            fit_prior = bestPara['fit_prior'], \n",
    "                            class_prior = bestPara['class_prior']   )\n",
    "    multiNB.fit(trainX, trainy)\n",
    "    predicty = multiNB.predict(validX)\n",
    "    tn, fp, fn, tp = confusion_matrix(validy, predicty).ravel()\n",
    "    result.append([fp/(fp+tn), fn/(fn+tp), (fn+fp)/(tn+fp+fn+tp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgrate = np.mean(result, axis = 0)\n",
    "finalresult = np.vstack((np.array(result),avgrate))\n",
    "resultDF = pandas.DataFrame(finalresult)\n",
    "resultDF.columns = ['FPR', 'FNR', 'Overall Err']\n",
    "resultDF.index = ['fold %s' % str(i) for i in range(1,6)] + ['Average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              FPR       FNR  Overall Err\n",
      "fold 1   0.147059  0.254237     0.186335\n",
      "fold 2   0.207447  0.287313     0.240683\n",
      "fold 3   0.175060  0.268722     0.208075\n",
      "fold 4   0.208000  0.211896     0.209627\n",
      "fold 5   0.205962  0.243636     0.222050\n",
      "Average  0.188706  0.253161     0.213354\n"
     ]
    }
   ],
   "source": [
    "print(resultDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final Multinomial Naive Bayes Model Training on All Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=[0.3, 0.7], fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiNB = MultinomialNB(alpha = bestPara['alpha'], fit_prior = bestPara['fit_prior'], class_prior = bestPara['class_prior'])\n",
    "multiNB.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation on Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Multinomial Naive Bayes) FPR: 0.172, FNR: 0.270, Overall Error: 0.210\n"
     ]
    }
   ],
   "source": [
    "predicty = multiNB.predict(testX)\n",
    "tn, fp, fn, tp = confusion_matrix(testy, predicty).ravel()\n",
    "print('(Multinomial Naive Bayes) FPR: %.3f, FNR: %.3f, Overall Error: %.3f' % (fp/(fp+tn), fn/(fn+tp), (fn+fp)/(tn+fp+fn+tp)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
